{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-30T11:28:39.933512Z",
     "start_time": "2025-04-30T11:28:31.181240Z"
    }
   },
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import ConnectionConfig as cc\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import col, collect_list, regexp_replace, split, trim\n",
    "\n",
    "cc.setupEnvironment()\n",
    "cc.set_connectionProfile(\"veloDB\")\n",
    "\n",
    "spark = cc.startLocalCluster(\"Weather_Data\", 4)\n",
    "spark.getActiveSession()\n",
    "\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T11:28:42.257875Z",
     "start_time": "2025-04-30T11:28:42.249721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_openmeteo_data(lat, lon, timestamp, zipcode):\n",
    "    dt = to_datetime(timestamp)\n",
    "    date_str = dt.strftime(\"%Y-%m-%d\")\n",
    "    hour_index = dt.hour\n",
    "\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": date_str,\n",
    "        \"end_date\": date_str,\n",
    "        \"hourly\": \"temperature_2m,precipitation,weathercode\",\n",
    "        \"timezone\": \"auto\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Cannot fetch: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    data = response.json()\n",
    "    try:\n",
    "        temperature = data[\"hourly\"][\"temperature_2m\"][hour_index]\n",
    "        precipitation = data[\"hourly\"][\"precipitation\"][hour_index]\n",
    "        code = data[\"hourly\"][\"weathercode\"][hour_index]\n",
    "\n",
    "        weather_data = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"temperature\": temperature,\n",
    "            \"precipitation\": precipitation,\n",
    "            \"weather_code\": code,\n",
    "            \"zipCode\": int(zipcode),\n",
    "            \"weather_condition\": classify_weather(temperature, code, precipitation)\n",
    "        }\n",
    "        return weather_data\n",
    "\n",
    "    except (KeyError, IndexError):\n",
    "        print(\"No hourly weather\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_weather_condition(weather_data):\n",
    "    if not weather_data or \"main\" not in weather_data or \"weather\" not in weather_data or not weather_data[\"weather\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    temperature = weather_data[\"main\"].get(\"temperature\")\n",
    "    weather_main = weather_data[\"weather\"][0].get(\"main\", \"\").lower()\n",
    "    weather_description = weather_data[\"weather\"][0].get(\"description\", \"\").lower()\n",
    "\n",
    "    # Unpleasant: Any form of precipitation\n",
    "    precipitation_keywords = [\"rain\", \"snow\", \"drizzle\", \"thunderstorm\", \"sleet\"]\n",
    "    if any(keyword in weather_main or keyword in weather_description for keyword in precipitation_keywords):\n",
    "        return \"Unpleasant\"\n",
    "\n",
    "    # Pleasant: Temperature above 15Â°C and sunny\n",
    "    if temperature is not None and temperature > 15 and weather_main == \"clear\":\n",
    "        return \"Pleasant\"\n",
    "\n",
    "    # Neutral: All other conditions\n",
    "    return \"Neutral\"\n",
    "\n",
    "def classify_weather(temp, weather_code, precipitation):\n",
    "    if temp is None or weather_code is None:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    unpleasant_codes = {61, 63, 65, 66, 67, 80, 81, 82, 95, 96, 99}  # rainy/thunderstorms\n",
    "\n",
    "    if weather_code in unpleasant_codes or (precipitation is not None and precipitation > 0):\n",
    "        return \"Unpleasant\"\n",
    "    if temp > 15 and weather_code == 0:  # clear sky\n",
    "        return \"Pleasant\"\n",
    "    return \"Neutral\"\n",
    "\n",
    "def to_datetime(iso_timestamp):\n",
    "    return datetime.fromisoformat(str(iso_timestamp))"
   ],
   "id": "d3515186b1eae8d9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T11:28:51.231643Z",
     "start_time": "2025-04-30T11:28:42.271866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load rides, locks, and stations data\n",
    "df_rides = (spark.read\n",
    "            .format(\"jdbc\")\n",
    "            .option(\"driver\", cc.get_Property(\"driver\"))\n",
    "            .option(\"url\", cc.get_Property(\"url\"))\n",
    "            .option(\"dbtable\", \"rides\")\n",
    "            .option(\"user\", cc.get_Property(\"username\"))\n",
    "            .option(\"password\", cc.get_Property(\"password\"))\n",
    "            .load())\n",
    "df_locks = (spark.read\n",
    "            .format(\"jdbc\")\n",
    "            .option(\"driver\", cc.get_Property(\"driver\"))\n",
    "            .option(\"url\", cc.get_Property(\"url\"))\n",
    "            .option(\"user\", cc.get_Property(\"username\"))\n",
    "            .option(\"password\", cc.get_Property(\"password\"))\n",
    "            .option(\"dbtable\", \"locks\")\n",
    "            .load())\n",
    "df_stations = (spark.read\n",
    "               .format(\"jdbc\")\n",
    "               .option(\"driver\", cc.get_Property(\"driver\"))\n",
    "               .option(\"url\", cc.get_Property(\"url\"))\n",
    "               .option(\"user\", cc.get_Property(\"username\"))\n",
    "               .option(\"password\", cc.get_Property(\"password\"))\n",
    "               .option(\"dbtable\", \"stations\")\n",
    "               .load())\n",
    "\n",
    "df_rides_with_stations = df_rides.alias(\"r\") \\\n",
    "    .join(df_locks.alias(\"l\"), col(\"r.startlockid\") == col(\"l.lockid\")) \\\n",
    "    .join(df_stations.alias(\"s\"), col(\"l.stationid\") == col(\"s.stationid\")) \\\n",
    "    .select(\n",
    "    col(\"r.rideid\"),\n",
    "    col(\"r.starttime\"),\n",
    "    col(\"s.zipcode\").alias(\"start_zipcode\"),\n",
    "    col(\"s.gpscoord\"),\n",
    "    trim(split(regexp_replace(\"s.gpscoord\", r\"[()]\", \"\"), \",\")[0]).cast(\"double\").alias(\"latitude\"),\n",
    "    trim(split(regexp_replace(\"s.gpscoord\", r\"[()]\", \"\"), \",\")[1]).cast(\"double\").alias(\"longitude\")\n",
    ")\n",
    "\n",
    "print(\"=== Schema ===\")\n",
    "df_rides_with_stations.printSchema()\n",
    "print(\"=== Data ===\")\n",
    "df_rides_with_stations.show()"
   ],
   "id": "7ce62ac5fd679796",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Schema ===\n",
      "root\n",
      " |-- rideid: integer (nullable = true)\n",
      " |-- starttime: timestamp (nullable = true)\n",
      " |-- start_zipcode: string (nullable = true)\n",
      " |-- gpscoord: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n",
      "=== Data ===\n",
      "+-------+-------------------+-------------+-----------------+--------+---------+\n",
      "| rideid|          starttime|start_zipcode|         gpscoord|latitude|longitude|\n",
      "+-------+-------------------+-------------+-----------------+--------+---------+\n",
      "|2043020|2021-09-05 12:04:36|         2000|(51.2195,4.41164)| 51.2195|  4.41164|\n",
      "|2043029|2021-09-01 11:35:23|         2100|(51.2293,4.46783)| 51.2293|  4.46783|\n",
      "|2043034|2021-09-01 11:38:46|         2060|(51.2201,4.43266)| 51.2201|  4.43266|\n",
      "|2043038|2021-09-01 11:11:24|         2140|(51.2083,4.44597)| 51.2083|  4.44597|\n",
      "|2043041|2021-09-01 11:15:13|         2000|(51.2281,4.41159)| 51.2281|  4.41159|\n",
      "|2043045|2021-09-01 11:23:33|         2000|(51.2098,4.39089)| 51.2098|  4.39089|\n",
      "|2043047|2021-09-01 11:43:31|         2100|(51.2192,4.46001)| 51.2192|  4.46001|\n",
      "|2043050|2021-09-05 12:53:08|         2660|(51.1735,4.35216)| 51.1735|  4.35216|\n",
      "|2043052|2021-09-05 12:39:30|         2000|(51.2262,4.40963)| 51.2262|  4.40963|\n",
      "|2043053|2021-09-01 11:17:21|         2610|(51.1753,4.41892)| 51.1753|  4.41892|\n",
      "|2043060|2021-09-01 11:38:31|         2000|(51.2221,4.41834)| 51.2221|  4.41834|\n",
      "|2043061|2021-09-05 12:49:37|         2000|(51.2229,4.40621)| 51.2229|  4.40621|\n",
      "|2043063|2021-09-01 11:22:12|         2020|(51.1886,4.37268)| 51.1886|  4.37268|\n",
      "|2043065|2021-09-01 11:22:38|         2000|(51.2098,4.39089)| 51.2098|  4.39089|\n",
      "|2043067|2021-09-01 11:36:03|         2140|  (51.21,4.42741)|   51.21|  4.42741|\n",
      "|2043069|2021-09-01 11:12:52|         2018|   (51.2173,4.42)| 51.2173|     4.42|\n",
      "|2043072|2021-09-01 11:17:04|         2060| (51.2261,4.4234)| 51.2261|   4.4234|\n",
      "|2043078|2021-09-01 11:57:26|         2030| (51.261,4.42016)|  51.261|  4.42016|\n",
      "|2043083|2021-09-01 11:52:08|         2100| (51.2205,4.4692)| 51.2205|   4.4692|\n",
      "|2043084|2021-09-01 11:58:31|         2060| (51.2261,4.4234)| 51.2261|   4.4234|\n",
      "+-------+-------------------+-------------+-----------------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T11:31:43.780327Z",
     "start_time": "2025-04-30T11:28:51.287710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs(\"weather\", exist_ok=True)\n",
    "\n",
    "postal_code_timestamps = df_rides_with_stations.groupBy(\"start_zipcode\") \\\n",
    "    .agg(collect_list(\"starttime\").alias(\"timestamps\"),\n",
    "         collect_list(\"latitude\").alias(\"latitudes\"),\n",
    "         collect_list(\"longitude\").alias(\"longitudes\")) \\\n",
    "    .collect()\n",
    "\n",
    "for row in postal_code_timestamps:\n",
    "    start_zipcode = row[\"start_zipcode\"]\n",
    "    timestamps = row[\"timestamps\"]\n",
    "    latitudes = row[\"latitudes\"]\n",
    "    longitudes = row[\"longitudes\"]\n",
    "\n",
    "    if len(timestamps) < 3:\n",
    "        additional_timestamps = [datetime.now() - timedelta(hours=i) for i in range(3 - len(timestamps))]\n",
    "        timestamps.extend(additional_timestamps)\n",
    "\n",
    "    for i in range(3):\n",
    "        timestamp = timestamps[i]\n",
    "        latitude = latitudes[i]\n",
    "        longitude = longitudes[i]\n",
    "        weather_data = fetch_openmeteo_data(latitude, longitude, timestamp, start_zipcode)\n",
    "        if weather_data:\n",
    "            formatted_timestamp = timestamp.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "            filename = f\"weather/{start_zipcode}_{formatted_timestamp}.json\"\n",
    "            with open(filename, \"w\") as f:\n",
    "                json.dump(weather_data, f, indent=4, default=str)\n",
    "            print(f\"Saved weather data for {start_zipcode} at {timestamp} to {filename}\")\n",
    "\n",
    "        time.sleep(4)\n",
    "\n",
    "spark.stop()"
   ],
   "id": "cb80c5f13cec453e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weather data for 2100 at 2021-09-01 11:35:23 to weather/2100_2021-09-01_11-35-23.json\n",
      "Saved weather data for 2100 at 2021-09-01 11:43:31 to weather/2100_2021-09-01_11-43-31.json\n",
      "Saved weather data for 2100 at 2021-09-01 11:52:08 to weather/2100_2021-09-01_11-52-08.json\n",
      "Saved weather data for 2060 at 2021-09-01 11:38:46 to weather/2060_2021-09-01_11-38-46.json\n",
      "Saved weather data for 2060 at 2021-09-01 11:17:04 to weather/2060_2021-09-01_11-17-04.json\n",
      "Saved weather data for 2060 at 2021-09-01 11:58:31 to weather/2060_2021-09-01_11-58-31.json\n",
      "Saved weather data for 2140 at 2021-09-01 11:11:24 to weather/2140_2021-09-01_11-11-24.json\n",
      "Saved weather data for 2140 at 2021-09-01 11:36:03 to weather/2140_2021-09-01_11-36-03.json\n",
      "Saved weather data for 2140 at 2021-09-01 12:56:13 to weather/2140_2021-09-01_12-56-13.json\n",
      "Saved weather data for 2170 at 2021-09-01 12:11:42 to weather/2170_2021-09-01_12-11-42.json\n",
      "Saved weather data for 2170 at 2021-09-05 14:32:45 to weather/2170_2021-09-05_14-32-45.json\n",
      "Saved weather data for 2170 at 2021-09-05 15:29:59 to weather/2170_2021-09-05_15-29-59.json\n",
      "Saved weather data for 2050 at 2021-09-05 14:00:00 to weather/2050_2021-09-05_14-00-00.json\n",
      "Saved weather data for 2050 at 2021-09-05 15:36:21 to weather/2050_2021-09-05_15-36-21.json\n",
      "Saved weather data for 2050 at 2021-09-01 18:59:51 to weather/2050_2021-09-01_18-59-51.json\n",
      "Saved weather data for 2660 at 2021-09-05 12:53:08 to weather/2660_2021-09-05_12-53-08.json\n",
      "Saved weather data for 2660 at 2021-09-01 11:10:16 to weather/2660_2021-09-01_11-10-16.json\n",
      "Saved weather data for 2660 at 2021-09-05 13:24:24 to weather/2660_2021-09-05_13-24-24.json\n",
      "Saved weather data for 2020 at 2021-09-01 11:22:12 to weather/2020_2021-09-01_11-22-12.json\n",
      "Saved weather data for 2020 at 2021-09-01 17:50:25 to weather/2020_2021-09-01_17-50-25.json\n",
      "Saved weather data for 2020 at 2021-09-01 23:43:58 to weather/2020_2021-09-01_23-43-58.json\n",
      "Saved weather data for 2018 at 2021-09-01 11:12:52 to weather/2018_2021-09-01_11-12-52.json\n",
      "Saved weather data for 2018 at 2021-09-01 11:27:06 to weather/2018_2021-09-01_11-27-06.json\n",
      "Saved weather data for 2018 at 2021-09-01 12:07:38 to weather/2018_2021-09-01_12-07-38.json\n",
      "Saved weather data for 2030 at 2021-09-01 11:57:26 to weather/2030_2021-09-01_11-57-26.json\n",
      "Saved weather data for 2030 at 2021-09-01 12:20:57 to weather/2030_2021-09-01_12-20-57.json\n",
      "Saved weather data for 2030 at 2021-09-01 13:50:29 to weather/2030_2021-09-01_13-50-29.json\n",
      "Saved weather data for 2600 at 2021-09-01 12:10:32 to weather/2600_2021-09-01_12-10-32.json\n",
      "Saved weather data for 2600 at 2021-09-05 12:46:54 to weather/2600_2021-09-05_12-46-54.json\n",
      "Saved weather data for 2600 at 2021-09-05 13:42:03 to weather/2600_2021-09-05_13-42-03.json\n",
      "Saved weather data for 2000 at 2021-09-05 12:04:36 to weather/2000_2021-09-05_12-04-36.json\n",
      "Saved weather data for 2000 at 2021-09-01 11:15:13 to weather/2000_2021-09-01_11-15-13.json\n",
      "Saved weather data for 2000 at 2021-09-01 11:23:33 to weather/2000_2021-09-01_11-23-33.json\n",
      "Saved weather data for 2610 at 2021-09-01 11:17:21 to weather/2610_2021-09-01_11-17-21.json\n",
      "Saved weather data for 2610 at 2021-09-01 11:35:30 to weather/2610_2021-09-01_11-35-30.json\n",
      "Saved weather data for 2610 at 2021-09-05 13:02:38 to weather/2610_2021-09-05_13-02-38.json\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
