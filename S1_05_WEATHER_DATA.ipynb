{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-14T07:36:28.733698Z",
     "start_time": "2025-05-14T07:35:38.295375Z"
    }
   },
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import ConnectionConfig as cc\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import col, collect_list, regexp_replace, split, trim\n",
    "\n",
    "cc.setupEnvironment()\n",
    "cc.set_connectionProfile(\"veloDB\")\n",
    "\n",
    "spark = cc.startLocalCluster(\"Weather_Data\", 4)\n",
    "spark.getActiveSession()\n",
    "\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T07:36:28.771149Z",
     "start_time": "2025-05-14T07:36:28.755761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_openmeteo_data(lat, lon, timestamp, zipcode):\n",
    "    dt = to_datetime(timestamp)\n",
    "    date_str = dt.strftime(\"%Y-%m-%d\")\n",
    "    hour_index = dt.hour\n",
    "\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": date_str,\n",
    "        \"end_date\": date_str,\n",
    "        \"hourly\": \"temperature_2m,precipitation,weathercode\",\n",
    "        \"timezone\": \"auto\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params, timeout=10)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Cannot fetch: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    data = response.json()\n",
    "    try:\n",
    "        temperature = data[\"hourly\"][\"temperature_2m\"][hour_index]\n",
    "        precipitation = data[\"hourly\"][\"precipitation\"][hour_index]\n",
    "        code = data[\"hourly\"][\"weathercode\"][hour_index]\n",
    "\n",
    "        weather_data = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"temperature\": temperature,\n",
    "            \"precipitation\": precipitation,\n",
    "            \"weather_code\": code,\n",
    "            \"zipCode\": int(zipcode),\n",
    "            \"weather_condition\": classify_weather(temperature, code, precipitation)\n",
    "        }\n",
    "        return weather_data\n",
    "\n",
    "    except (KeyError, IndexError):\n",
    "        print(\"No hourly weather\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_weather_condition(weather_data):\n",
    "    if not weather_data or \"main\" not in weather_data or \"weather\" not in weather_data or not weather_data[\"weather\"]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    temperature = weather_data[\"main\"].get(\"temperature\")\n",
    "    weather_main = weather_data[\"weather\"][0].get(\"main\", \"\").lower()\n",
    "    weather_description = weather_data[\"weather\"][0].get(\"description\", \"\").lower()\n",
    "\n",
    "    # Unpleasant: Any form of precipitation\n",
    "    precipitation_keywords = [\"rain\", \"snow\", \"drizzle\", \"thunderstorm\", \"sleet\"]\n",
    "    if any(keyword in weather_main or keyword in weather_description for keyword in precipitation_keywords):\n",
    "        return \"Unpleasant\"\n",
    "\n",
    "    # Pleasant: Temperature above 15Â°C and sunny\n",
    "    if temperature is not None and temperature > 15 and weather_main == \"clear\":\n",
    "        return \"Pleasant\"\n",
    "\n",
    "    # Neutral: All other conditions\n",
    "    return \"Neutral\"\n",
    "\n",
    "def classify_weather(temp, weather_code, precipitation):\n",
    "    if temp is None or weather_code is None:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    unpleasant_codes = {61, 63, 65, 66, 67, 80, 81, 82, 95, 96, 99}  # rainy/thunderstorms\n",
    "\n",
    "    if weather_code in unpleasant_codes or (precipitation is not None and precipitation > 0):\n",
    "        return \"Unpleasant\"\n",
    "    if temp > 15 and weather_code == 0:  # clear sky\n",
    "        return \"Pleasant\"\n",
    "    return \"Neutral\"\n",
    "\n",
    "def to_datetime(iso_timestamp):\n",
    "    return datetime.fromisoformat(str(iso_timestamp))"
   ],
   "id": "d3515186b1eae8d9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T07:36:32.154881Z",
     "start_time": "2025-05-14T07:36:28.788165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#EXTRACT\n",
    "df_rides = (spark.read\n",
    "            .format(\"jdbc\")\n",
    "            .option(\"driver\", cc.get_Property(\"driver\"))\n",
    "            .option(\"url\", cc.get_Property(\"url\"))\n",
    "            .option(\"dbtable\", \"rides\")\n",
    "            .option(\"user\", cc.get_Property(\"username\"))\n",
    "            .option(\"password\", cc.get_Property(\"password\"))\n",
    "            .load())\n",
    "df_locks = (spark.read\n",
    "            .format(\"jdbc\")\n",
    "            .option(\"driver\", cc.get_Property(\"driver\"))\n",
    "            .option(\"url\", cc.get_Property(\"url\"))\n",
    "            .option(\"user\", cc.get_Property(\"username\"))\n",
    "            .option(\"password\", cc.get_Property(\"password\"))\n",
    "            .option(\"dbtable\", \"locks\")\n",
    "            .load())\n",
    "df_stations = (spark.read\n",
    "               .format(\"jdbc\")\n",
    "               .option(\"driver\", cc.get_Property(\"driver\"))\n",
    "               .option(\"url\", cc.get_Property(\"url\"))\n",
    "               .option(\"user\", cc.get_Property(\"username\"))\n",
    "               .option(\"password\", cc.get_Property(\"password\"))\n",
    "               .option(\"dbtable\", \"stations\")\n",
    "               .load())"
   ],
   "id": "141d154b07a1fa2b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T07:36:51.730363Z",
     "start_time": "2025-05-14T07:36:37.234880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TRANSFORM\n",
    "df_rides_with_stations = df_rides.alias(\"r\") \\\n",
    "    .join(df_locks.alias(\"l\"), col(\"r.startlockid\") == col(\"l.lockid\")) \\\n",
    "    .join(df_stations.alias(\"s\"), col(\"l.stationid\") == col(\"s.stationid\")) \\\n",
    "    .select(\n",
    "    col(\"r.rideid\"),\n",
    "    col(\"r.starttime\"),\n",
    "    col(\"s.zipcode\").alias(\"start_zipcode\"),\n",
    "    col(\"s.gpscoord\"),\n",
    "    trim(split(regexp_replace(\"s.gpscoord\", r\"[()]\", \"\"), \",\")[0]).cast(\"double\").alias(\"latitude\"),\n",
    "    trim(split(regexp_replace(\"s.gpscoord\", r\"[()]\", \"\"), \",\")[1]).cast(\"double\").alias(\"longitude\")\n",
    ")\n",
    "\n",
    "print(\"=== Schema ===\")\n",
    "df_rides_with_stations.printSchema()\n",
    "print(\"=== Data ===\")\n",
    "df_rides_with_stations.show()"
   ],
   "id": "7ce62ac5fd679796",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Schema ===\n",
      "root\n",
      " |-- rideid: integer (nullable = true)\n",
      " |-- starttime: timestamp (nullable = true)\n",
      " |-- start_zipcode: string (nullable = true)\n",
      " |-- gpscoord: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n",
      "=== Data ===\n",
      "+------+-------------------+-------------+-----------------+--------+---------+\n",
      "|rideid|          starttime|start_zipcode|         gpscoord|latitude|longitude|\n",
      "+------+-------------------+-------------+-----------------+--------+---------+\n",
      "|     4|2015-09-22 00:00:00|         2018|(51.2034,4.39221)| 51.2034|  4.39221|\n",
      "|     9|2015-09-22 00:00:00|         2000|(51.2187,4.40066)| 51.2187|  4.40066|\n",
      "|    12|2015-09-22 00:00:00|         2000|(51.2092,4.40293)| 51.2092|  4.40293|\n",
      "|    13|2015-09-22 00:00:00|         2610|(51.1771,4.39978)| 51.1771|  4.39978|\n",
      "|    18|2019-09-22 08:41:48|         2018|(51.2034,4.39221)| 51.2034|  4.39221|\n",
      "|    23|2019-09-22 08:23:27|         2000|(51.2187,4.40066)| 51.2187|  4.40066|\n",
      "|    26|2019-09-22 08:14:52|         2000|(51.2092,4.40293)| 51.2092|  4.40293|\n",
      "|    27|2019-09-22 08:51:13|         2610|(51.1771,4.39978)| 51.1771|  4.39978|\n",
      "|    34|2019-09-22 08:30:44|         2018|(51.2016,4.42361)| 51.2016|  4.42361|\n",
      "|    36|2019-09-22 08:08:45|         2030|(51.2402,4.40841)| 51.2402|  4.40841|\n",
      "|    42|2019-09-22 08:37:36|         2000|(51.2295,4.41138)| 51.2295|  4.41138|\n",
      "|    43|2019-09-22 08:03:38|         2140|(51.2186,4.43864)| 51.2186|  4.43864|\n",
      "|    45|2019-09-22 08:19:04|         2018|(51.1968,4.40575)| 51.1968|  4.40575|\n",
      "|    50|2019-09-22 08:25:54|         2000|(51.2295,4.41138)| 51.2295|  4.41138|\n",
      "|    53|2019-09-22 08:49:18|         2140|  (51.2039,4.452)| 51.2039|    4.452|\n",
      "|    65|2019-09-22 08:08:47|         2170|(51.2509,4.44224)| 51.2509|  4.44224|\n",
      "|    74|2019-09-22 08:49:02|         2018| (51.213,4.42164)|  51.213|  4.42164|\n",
      "|    76|2019-09-22 08:33:43|         2100|(51.2329,4.44448)| 51.2329|  4.44448|\n",
      "|    77|2019-09-22 08:24:51|         2018|   (51.2173,4.42)| 51.2173|     4.42|\n",
      "|    86|2019-09-22 08:42:03|         2060| (51.228,4.41899)|  51.228|  4.41899|\n",
      "+------+-------------------+-------------+-----------------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T07:37:16.346498Z",
     "start_time": "2025-05-14T07:36:52.458012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TRANSFORM\n",
    "os.makedirs(\"weather\", exist_ok=True)\n",
    "\n",
    "postal_code_timestamps = df_rides_with_stations.groupBy(\"start_zipcode\") \\\n",
    "    .agg(collect_list(\"starttime\").alias(\"timestamps\"),\n",
    "         collect_list(\"latitude\").alias(\"latitudes\"),\n",
    "         collect_list(\"longitude\").alias(\"longitudes\")) \\\n",
    "    .collect()"
   ],
   "id": "57375ae23a6720b0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T07:39:55.286809Z",
     "start_time": "2025-05-14T07:37:17.719565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#LOAD\n",
    "for row in postal_code_timestamps:\n",
    "    start_zipcode = row[\"start_zipcode\"]\n",
    "    timestamps = row[\"timestamps\"]\n",
    "    latitudes = row[\"latitudes\"]\n",
    "    longitudes = row[\"longitudes\"]\n",
    "\n",
    "    if len(timestamps) < 3:\n",
    "        additional_timestamps = [datetime.now() - timedelta(hours=i) for i in range(3 - len(timestamps))]\n",
    "        timestamps.extend(additional_timestamps)\n",
    "\n",
    "    for i in range(3):\n",
    "        timestamp = timestamps[i]\n",
    "        latitude = latitudes[i]\n",
    "        longitude = longitudes[i]\n",
    "        weather_data = fetch_openmeteo_data(latitude, longitude, timestamp, start_zipcode)\n",
    "        if weather_data:\n",
    "            formatted_timestamp = timestamp.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "            filename = f\"weather/{start_zipcode}_{formatted_timestamp}.json\"\n",
    "            with open(filename, \"w\") as f:\n",
    "                json.dump(weather_data, f, indent=4, default=str)\n",
    "            print(f\"Saved weather data for {start_zipcode} at {timestamp} to {filename}\")\n",
    "\n",
    "        time.sleep(4)\n",
    "\n",
    "spark.stop()"
   ],
   "id": "cb80c5f13cec453e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weather data for 2140 at 2019-09-22 08:03:38 to weather/2140_2019-09-22_08-03-38.json\n",
      "Saved weather data for 2140 at 2019-09-22 08:49:18 to weather/2140_2019-09-22_08-49-18.json\n",
      "Saved weather data for 2140 at 2019-09-22 08:11:14 to weather/2140_2019-09-22_08-11-14.json\n",
      "Saved weather data for 2170 at 2019-09-22 08:08:47 to weather/2170_2019-09-22_08-08-47.json\n",
      "Saved weather data for 2170 at 2019-09-22 09:10:02 to weather/2170_2019-09-22_09-10-02.json\n",
      "Saved weather data for 2170 at 2019-09-22 10:57:35 to weather/2170_2019-09-22_10-57-35.json\n",
      "Saved weather data for 2100 at 2019-09-22 08:33:43 to weather/2100_2019-09-22_08-33-43.json\n",
      "Saved weather data for 2100 at 2019-09-22 08:34:50 to weather/2100_2019-09-22_08-34-50.json\n",
      "Saved weather data for 2100 at 2019-09-22 08:36:21 to weather/2100_2019-09-22_08-36-21.json\n",
      "Saved weather data for 2060 at 2019-09-22 08:42:03 to weather/2060_2019-09-22_08-42-03.json\n",
      "Saved weather data for 2060 at 2019-09-22 08:37:23 to weather/2060_2019-09-22_08-37-23.json\n",
      "Saved weather data for 2060 at 2019-09-22 08:15:15 to weather/2060_2019-09-22_08-15-15.json\n",
      "Saved weather data for 2050 at 2019-09-22 08:36:14 to weather/2050_2019-09-22_08-36-14.json\n",
      "Saved weather data for 2050 at 2019-09-22 08:29:24 to weather/2050_2019-09-22_08-29-24.json\n",
      "Saved weather data for 2050 at 2019-09-22 10:14:53 to weather/2050_2019-09-22_10-14-53.json\n",
      "Saved weather data for 2018 at 2015-09-22 00:00:00 to weather/2018_2015-09-22_00-00-00.json\n",
      "Saved weather data for 2018 at 2019-09-22 08:41:48 to weather/2018_2019-09-22_08-41-48.json\n",
      "Saved weather data for 2018 at 2019-09-22 08:30:44 to weather/2018_2019-09-22_08-30-44.json\n",
      "Saved weather data for 2030 at 2019-09-22 08:08:45 to weather/2030_2019-09-22_08-08-45.json\n",
      "Saved weather data for 2030 at 2019-09-22 08:36:44 to weather/2030_2019-09-22_08-36-44.json\n",
      "Saved weather data for 2030 at 2019-09-22 08:43:51 to weather/2030_2019-09-22_08-43-51.json\n",
      "Saved weather data for 2020 at 2019-09-22 08:57:15 to weather/2020_2019-09-22_08-57-15.json\n",
      "Saved weather data for 2020 at 2019-09-22 09:57:25 to weather/2020_2019-09-22_09-57-25.json\n",
      "Saved weather data for 2020 at 2019-09-22 09:35:37 to weather/2020_2019-09-22_09-35-37.json\n",
      "Saved weather data for 2600 at 2019-09-22 08:27:12 to weather/2600_2019-09-22_08-27-12.json\n",
      "Saved weather data for 2600 at 2019-09-22 08:23:51 to weather/2600_2019-09-22_08-23-51.json\n",
      "Saved weather data for 2600 at 2019-09-22 08:43:43 to weather/2600_2019-09-22_08-43-43.json\n",
      "Saved weather data for 2660 at 2019-09-22 08:09:34 to weather/2660_2019-09-22_08-09-34.json\n",
      "Saved weather data for 2660 at 2019-09-22 09:26:11 to weather/2660_2019-09-22_09-26-11.json\n",
      "Saved weather data for 2660 at 2019-09-22 10:22:27 to weather/2660_2019-09-22_10-22-27.json\n",
      "Saved weather data for 2000 at 2015-09-22 00:00:00 to weather/2000_2015-09-22_00-00-00.json\n",
      "Saved weather data for 2000 at 2015-09-22 00:00:00 to weather/2000_2015-09-22_00-00-00.json\n",
      "Saved weather data for 2000 at 2019-09-22 08:23:27 to weather/2000_2019-09-22_08-23-27.json\n",
      "Saved weather data for 2610 at 2015-09-22 00:00:00 to weather/2610_2015-09-22_00-00-00.json\n",
      "Saved weather data for 2610 at 2019-09-22 08:51:13 to weather/2610_2019-09-22_08-51-13.json\n",
      "Saved weather data for 2610 at 2019-09-22 08:24:57 to weather/2610_2019-09-22_08-24-57.json\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
