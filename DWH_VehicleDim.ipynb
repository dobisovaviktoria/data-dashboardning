{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T15:31:50.520624Z",
     "start_time": "2025-02-27T15:31:50.412096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##Extract\n",
    "import random\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, functions\n",
    "import ConnectionConfig as cc\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Set up environment\n",
    "cc.setupEnvironment()\n",
    "cc.listEnvironment()\n",
    "\n",
    "# Start local Spark cluster\n",
    "spark = cc.startLocalCluster(\"vehicle_dim\")\n",
    "spark.getActiveSession()  # To get the active Spark session\n",
    "\n",
    "# Extract data from the \"vehicles\" table\n",
    "cc.set_connectionProfile(\"veloDB\")\n",
    "\n",
    "# EXTRACT: Loading data from the vehicles table into df_operational_vehicle_dim\n",
    "df_operational_vehicle_dim = (spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", cc.get_Property(\"driver\")) \n",
    "    .option(\"url\", cc.create_jdbc()) \n",
    "    .option(\"dbtable\", \"vehicles\") \n",
    "    .option(\"user\", cc.get_Property(\"username\")) \n",
    "    .option(\"password\", cc.get_Property(\"password\")) \n",
    "    .option(\"partitionColumn\", \"vehicleid\") \n",
    "    .option(\"numPartitions\", 4) \n",
    "    .option(\"lowerBound\", 1000) \n",
    "    .option(\"upperBound\", 5000) \n",
    "    .load())\n",
    "\n",
    "# Show the first 20 rows of the operational data to confirm extraction\n",
    "df_operational_vehicle_dim.show(20)\n"
   ],
   "id": "8417a59c857e04ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLUSERSPROFILE: C:\\ProgramData\n",
      "APPDATA: C:\\Users\\User\\AppData\\Roaming\n",
      "COMMONPROGRAMFILES: C:\\Program Files\\Common Files\n",
      "COMMONPROGRAMFILES(X86): C:\\Program Files (x86)\\Common Files\n",
      "COMMONPROGRAMW6432: C:\\Program Files\\Common Files\n",
      "COMPUTERNAME: MSI\n",
      "COMSPEC: C:\\WINDOWS\\system32\\cmd.exe\n",
      "CONFIGSETROOT: C:\\WINDOWS\\ConfigSetRoot\n",
      "DRIVERDATA: C:\\Windows\\System32\\Drivers\\DriverData\n",
      "EFC_10468: 1\n",
      "FPS_BROWSER_APP_PROFILE_STRING: Internet Explorer\n",
      "FPS_BROWSER_USER_PROFILE_STRING: Default\n",
      "HOMEDRIVE: C:\n",
      "HOMEPATH: \\Users\\User\n",
      "IPY_INTERRUPT_EVENT: 1680\n",
      "JPY_INTERRUPT_EVENT: 1680\n",
      "JPY_PARENT_PID: 1684\n",
      "JPY_SESSION_NAME: DWH_VehicleDim.ipynb\n",
      "LANG: en_US.UTF-8\n",
      "LANGUAGE: \n",
      "LC_ALL: en_US.UTF-8\n",
      "LOCALAPPDATA: C:\\Users\\User\\AppData\\Local\n",
      "LOGONSERVER: \\\\MSI\n",
      "NUMBER_OF_PROCESSORS: 20\n",
      "ONEDRIVE: C:\\Users\\User\\OneDrive\n",
      "ONEDRIVECONSUMER: C:\\Users\\User\\OneDrive\n",
      "OS: Windows_NT\n",
      "PATH: D:\\KdG\\Year 2\\Integration\\sparkdelta\\venv\\Scripts;C:\\Program Files\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\Program Files\\Cloudflare\\Cloudflare WARP\\;C:\\Program Files\\Git\\cmd;C:\\Program Files\\PuTTY\\;D:\\KdG\\Programming 2\\NodeJs\\;C:\\Program Files\\Docker\\Docker\\resources\\bin;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Launcher\\;C:\\Users\\User\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\User\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\User\\AppData\\Local\\JetBrains\\Toolbox\\scripts;C:\\Users\\User\\AppData\\Roaming\\npm;C:\\tools\\bigdatatools\\spark-3.5.2-bin-hadoop3\\bin;C:\\tools\\bigdatatools\\hadoop-3.4.0-win10-x64\\bin;C:\\Program Files\\Java\\jdk-17\\bin;C:\\tools\\bigdatatools\\spark-3.5.2-bin-hadoop3\\bin;C:\\tools\\bigdatatools\\hadoop-3.4.0-win10-x64\\bin;C:\\Program Files\\Java\\jdk-17\\bin;C:\\tools\\bigdatatools\\spark-3.5.2-bin-hadoop3\\bin;C:\\tools\\bigdatatools\\hadoop-3.4.0-win10-x64\\bin;C:\\Program Files\\Java\\jdk-17\\bin;C:\\tools\\bigdatatools\\spark-3.5.2-bin-hadoop3\\bin;C:\\tools\\bigdatatools\\hadoop-3.4.0-win10-x64\\bin;C:\\Program Files\\Java\\jdk-17\\bin\n",
      "PATHEXT: .COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC\n",
      "PROCESSOR_ARCHITECTURE: AMD64\n",
      "PROCESSOR_IDENTIFIER: Intel64 Family 6 Model 154 Stepping 3, GenuineIntel\n",
      "PROCESSOR_LEVEL: 6\n",
      "PROCESSOR_REVISION: 9a03\n",
      "PROGRAMDATA: C:\\ProgramData\n",
      "PROGRAMFILES: C:\\Program Files\n",
      "PROGRAMFILES(X86): C:\\Program Files (x86)\n",
      "PROGRAMW6432: C:\\Program Files\n",
      "PROMPT: (venv) $P$G\n",
      "PSMODULEPATH: C:\\Program Files\\WindowsPowerShell\\Modules;C:\\WINDOWS\\system32\\WindowsPowerShell\\v1.0\\Modules\n",
      "PT8HOME: C:\\Program Files\\Cisco Packet Tracer 8.2.1\n",
      "PUBLIC: C:\\Users\\Public\n",
      "PYTHONPATH: D:\\KdG\\Year 2\\Sem2\\DataAI_Sem_2\\sparkdelta\n",
      "SESSIONNAME: Console\n",
      "SYSTEMDRIVE: C:\n",
      "SYSTEMROOT: C:\\WINDOWS\n",
      "TEMP: C:\\Users\\User\\AppData\\Local\\Temp\n",
      "TMP: C:\\Users\\User\\AppData\\Local\\Temp\n",
      "USERDOMAIN: MSI\n",
      "USERDOMAIN_ROAMINGPROFILE: MSI\n",
      "USERNAME: User\n",
      "USERPROFILE: C:\\Users\\User\n",
      "VBOX_MSI_INSTALL_PATH: C:\\Program Files\\Oracle\\VirtualBox\\\n",
      "VIRTUAL_ENV: D:\\KdG\\Year 2\\Integration\\sparkdelta\\venv\n",
      "WINDIR: C:\\WINDOWS\n",
      "ZES_ENABLE_SYSMAN: 1\n",
      "_OLD_VIRTUAL_PATH: C:\\Program Files\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\Program Files\\Cloudflare\\Cloudflare WARP\\;C:\\Program Files\\Git\\cmd;C:\\Program Files\\PuTTY\\;D:\\KdG\\Programming 2\\NodeJs\\;C:\\Program Files\\Docker\\Docker\\resources\\bin;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Launcher\\;C:\\Users\\User\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\User\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\User\\AppData\\Local\\JetBrains\\Toolbox\\scripts;C:\\Users\\User\\AppData\\Roaming\\npm\n",
      "_OLD_VIRTUAL_PROMPT: $P$G\n",
      "__PSLOCKDOWNPOLICY: 0\n",
      "PYDEVD_USE_FRAME_EVAL: NO\n",
      "TERM: xterm-color\n",
      "CLICOLOR: 1\n",
      "FORCE_COLOR: 1\n",
      "CLICOLOR_FORCE: 1\n",
      "PAGER: cat\n",
      "GIT_PAGER: cat\n",
      "MPLBACKEND: module://matplotlib_inline.backend_inline\n",
      "PYSPARK_PYTHON: python\n",
      "SPARK_HOME: C:\\tools\\bigdatatools\\spark-3.5.2-bin-hadoop3\n",
      "HADOOP_HOME: C:\\tools\\bigdatatools\\hadoop-3.4.0-win10-x64\n",
      "PYSPARK_HADOOP_VERSION: 3\n",
      "JAVA_HOME: C:\\Program Files\\Java\\jdk-17\\\n",
      "SPARK_AUTH_SOCKET_TIMEOUT: 15\n",
      "SPARK_BUFFER_SIZE: 65536\n",
      "+---------+------------+---------+-------------------+------+-----------------+\n",
      "|vehicleid|serialnumber|bikelotid|  lastmaintenanceon|lockid|         position|\n",
      "+---------+------------+---------+-------------------+------+-----------------+\n",
      "|        1|        1000|        1|2020-01-19 02:14:57|  NULL|(51.1968,4.40579)|\n",
      "|        2|        2000|        1|2020-03-08 01:49:24|  NULL|(51.2177,4.42075)|\n",
      "|        3|        3000|        1|2020-06-01 12:37:26|  1568|(51.1926,4.42151)|\n",
      "|        4|        4000|        1|2020-02-27 03:13:56|  NULL|(51.2311,4.41267)|\n",
      "|        5|        5000|        1|2021-03-21 03:38:31|  NULL|(51.2177,4.42075)|\n",
      "|        6|        6000|        1|2020-06-16 21:44:19|  NULL|(51.2195,4.41169)|\n",
      "|        7|        7000|        1|2019-10-01 10:29:21|  1556| (51.2273,4.4307)|\n",
      "|        8|        8000|        1|2019-12-06 17:09:49|  NULL|(51.2047,4.39625)|\n",
      "|        9|        9000|        1|2020-01-01 10:06:51|  NULL|(51.2058,4.41837)|\n",
      "|       10|       10000|        1|2019-12-12 09:04:02|  NULL|(51.2008,4.39421)|\n",
      "|       11|       11000|        1|2019-12-22 10:20:54|  NULL|(51.2148,4.39632)|\n",
      "|       12|       12000|        1|2019-10-21 17:55:13|  NULL|(51.2195,4.41169)|\n",
      "|       13|       13000|        1|2019-10-01 19:15:22|  NULL|(51.1968,4.40579)|\n",
      "|       14|       14000|        1|2020-08-10 20:43:37|  NULL|(51.2088,4.40834)|\n",
      "|       15|       15000|        1|2020-10-30 21:35:40|  NULL|(51.2224,4.43004)|\n",
      "|       16|       16000|        1|2023-09-12 17:14:09|  6840|(51.1692,4.36344)|\n",
      "|       17|       17000|        1|2019-10-09 11:54:35|  NULL|  (51.2281,4.409)|\n",
      "|       18|       18000|        1|2019-12-20 21:25:39|  NULL|(51.2104,4.38767)|\n",
      "|       19|       19000|        1|2023-09-05 19:27:31|  2142| (51.211,4.39035)|\n",
      "|       20|       20000|        1|2019-10-01 15:38:59|  NULL|(51.2047,4.39625)|\n",
      "+---------+------------+---------+-------------------+------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T15:31:50.787360Z",
     "start_time": "2025-02-27T15:31:50.528634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Trasform\n",
    "# Load tables from JDBC for bike lots and bike types\n",
    "df_bikelots = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", cc.create_jdbc()) \\\n",
    "    .option(\"driver\", cc.get_Property(\"driver\")) \\\n",
    "    .option(\"dbtable\", \"bikelots\") \\\n",
    "    .option(\"user\", cc.get_Property(\"username\")) \\\n",
    "    .option(\"password\", cc.get_Property(\"password\")) \\\n",
    "    .load()\n",
    "\n",
    "df_biketypes = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", cc.create_jdbc()) \\\n",
    "    .option(\"driver\", cc.get_Property(\"driver\")) \\\n",
    "    .option(\"dbtable\", \"bike_types\") \\\n",
    "    .option(\"user\", cc.get_Property(\"username\")) \\\n",
    "    .option(\"password\", cc.get_Property(\"password\")) \\\n",
    "    .load()\n",
    "\n",
    "df_vehicles = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", cc.create_jdbc()) \\\n",
    "    .option(\"driver\", cc.get_Property(\"driver\")) \\\n",
    "    .option(\"dbtable\", \"vehicles\") \\\n",
    "    .option(\"user\", cc.get_Property(\"username\")) \\\n",
    "    .option(\"password\", cc.get_Property(\"password\")) \\\n",
    "    .load()\n",
    "\n",
    "# Perform the JOIN operations to combine data\n",
    "# Join vehicles -> bikelots -> biketypes\n",
    "df_result = df_vehicles \\\n",
    "    .join(df_bikelots, df_vehicles.bikelotid == df_bikelots.bikelotid, \"inner\") \\\n",
    "    .join(df_biketypes, df_bikelots.biketypeid == df_biketypes.biketypeid, \"inner\") \\\n",
    "    .select(df_vehicles.vehicleid.alias(\"vehicle_id\"), df_biketypes.biketypedescription)\n",
    "\n",
    "# Show the resulting transformed DataFrame\n",
    "df_result.show()\n",
    "df_result.printSchema()  # Check the schema after transformation\n"
   ],
   "id": "15078749e807d6a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "|vehicle_id|biketypedescription|\n",
      "+----------+-------------------+\n",
      "|      3083|            Scooter|\n",
      "|      3084|            Scooter|\n",
      "|      3085|            Scooter|\n",
      "|      3086|            Scooter|\n",
      "|      3087|            Scooter|\n",
      "|      3088|            Scooter|\n",
      "|      3089|            Scooter|\n",
      "|      3090|            Scooter|\n",
      "|      3091|            Scooter|\n",
      "|      3092|            Scooter|\n",
      "|      3093|            Scooter|\n",
      "|      3094|            Scooter|\n",
      "|      3095|            Scooter|\n",
      "|      3096|            Scooter|\n",
      "|      3097|            Scooter|\n",
      "|      3098|            Scooter|\n",
      "|      3099|            Scooter|\n",
      "|      3100|            Scooter|\n",
      "|      3101|            Scooter|\n",
      "|      3102|            Scooter|\n",
      "+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- vehicle_id: integer (nullable = true)\n",
      " |-- biketypedescription: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T15:33:37.127074Z",
     "start_time": "2025-02-27T15:33:35.768543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Load\n",
    "# Save the transformed data to a Delta table\n",
    "spark.sql(\"DROP TABLE IF EXISTS vehicle_dim\")\n",
    "\n",
    "df_result.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .option(\"path\", \"file:/D:/KdG/Year%202/Sem2/DataAI_Sem_2/sparkdelta/velo-warehouse\") \\\n",
    "    .saveAsTable(\"vehicle_dim\")\n",
    "\n",
    "\n",
    "# Confirmation that the data has been saved to the Delta table\n",
    "print(\"Data successfully written to Delta table: vehicle_dim\")"
   ],
   "id": "424e96da6fa6d02a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to Delta table: vehicle_dim\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T15:31:50.924597400Z",
     "start_time": "2025-02-27T15:00:28.432644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Test\n",
    "# Query the saved Delta table\n",
    "spark.sql(\"SELECT * FROM vehicle_dim\").show()\n"
   ],
   "id": "a4acc6c0dd17d775",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "|vehicle_id|biketypedescription|\n",
      "+----------+-------------------+\n",
      "|      3083|            Scooter|\n",
      "|      3084|            Scooter|\n",
      "|      3085|            Scooter|\n",
      "|      3086|            Scooter|\n",
      "|      3087|            Scooter|\n",
      "|      3088|            Scooter|\n",
      "|      3089|            Scooter|\n",
      "|      3090|            Scooter|\n",
      "|      3091|            Scooter|\n",
      "|      3092|            Scooter|\n",
      "|      3093|            Scooter|\n",
      "|      3094|            Scooter|\n",
      "|      3095|            Scooter|\n",
      "|      3096|            Scooter|\n",
      "|      3097|            Scooter|\n",
      "|      3098|            Scooter|\n",
      "|      3099|            Scooter|\n",
      "|      3100|            Scooter|\n",
      "|      3101|            Scooter|\n",
      "|      3102|            Scooter|\n",
      "+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T15:31:50.925652Z",
     "start_time": "2025-02-27T15:01:12.875441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Using Spark SQL to count rows\n",
    "spark.sql(\"SELECT COUNT(*) FROM vehicle_dim\").show()"
   ],
   "id": "ad8c76e9403cc73c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    7000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T15:31:50.925652Z",
     "start_time": "2025-02-27T15:02:24.099824Z"
    }
   },
   "cell_type": "code",
   "source": "spark.sql(\"DESCRIBE FORMATTED vehicle_dim\").show(truncate=False)\n",
   "id": "75c4287e5a5298d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                        |comment|\n",
      "+----------------------------+---------------------------------------------------------------------------------+-------+\n",
      "|vehicle_id                  |int                                                                              |NULL   |\n",
      "|biketypedescription         |string                                                                           |NULL   |\n",
      "|                            |                                                                                 |       |\n",
      "|# Detailed Table Information|                                                                                 |       |\n",
      "|Name                        |spark_catalog.default.vehicle_dim                                                |       |\n",
      "|Type                        |EXTERNAL                                                                         |       |\n",
      "|Location                    |file:/D:/KdG/Year%202/Sem2/DataAI_Sem_2/sparkdelta/spark-warehouse/velo-warehouse|       |\n",
      "|Provider                    |delta                                                                            |       |\n",
      "|Table Properties            |[delta.minReaderVersion=1,delta.minWriterVersion=2]                              |       |\n",
      "+----------------------------+---------------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T15:31:50.925652Z",
     "start_time": "2025-02-27T15:06:09.833350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a temporary view from the Delta table\n",
    "spark.sql(\"CREATE OR REPLACE TEMP VIEW vehicle_dim_view AS SELECT * FROM vehicle_dim\")\n"
   ],
   "id": "19090ca7ccb8d5d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
